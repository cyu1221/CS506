{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#List of file names\n",
    "file_names = ['f1516_f3.csv','f1415_f3.csv','f1314_f3.csv','f1213_f3.csv','f1112_f3.csv','f1011_f3.csv','f0910_f3.csv',\n",
    "\t\t\t  'f0809_f3.csv','f0708_f3.csv','f0607_f3.csv','f0506_f3.csv','f0405_f3.csv','f0304_f3.csv','f0203_f3.csv',\n",
    "\t\t\t  'f0102_f3.csv','f0001_f3.csv','f9900f3.csv']\n",
    "\n",
    "#Columns of intrest\n",
    "colNames1316 = ['UNITID', 'F3A04', 'F3B01', 'F3B02', 'F3E02A1']\n",
    "colNames0613 = ['UNITID', 'F3A04', 'F3B01', 'F3B02', 'F3E02']\n",
    "colNames0506 = ['unitid', 'f3a04', 'f3b01', 'f3b02', 'f3e02']\n",
    "\n",
    "\n",
    "dfs = [\"\"]*17\n",
    "for i in range(len(file_names)):\n",
    "\tprint(file_names[i])\n",
    "\tdfs[i] = pd.read_csv(file_names[i], encoding='latin-1')\n",
    "\tif i < 3:\n",
    "\t\tdfs[i] = dfs[i][colNames1316]\n",
    "\telif i < 10:\n",
    "\t\tdfs[i] = dfs[i][colNames0613]\n",
    "\telse:\n",
    "\t\tdfs[i] = dfs[i][colNames0506]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID', 'ASSETS', 'REVENUE', 'EXPENSES', 'RESEARCH']\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID']+[file_names[i][1:5] + '_' + dfs[i].columns[j] for j in range(1,len(dfs[i].columns))]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i]['UNITID'] = dfs[i]['UNITID'].apply(lambda x: int(x))\n",
    "\n",
    "df_result = dfs[0]\n",
    "for i in range(1,len(dfs)):\n",
    "\tdf_result = pd.merge(df_result, dfs[i], left_on='UNITID', right_on='UNITID', how='inner')\n",
    "\n",
    "\n",
    "print(df_result)\n",
    "df_result.to_csv('./for_profit9916.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#List of file names\n",
    "file_names = ['f1516_f2.csv','f1415_f2.csv','f1314_f2.csv','f1213_f2.csv','f1112_f2.csv','f1011_f2.csv','f0910_f2.csv',\n",
    "\t\t\t  'f0809_f2.csv','f0708_f2.csv','f0607_f2.csv','f0506_f2.csv','f0405_f2.csv','f0304_f2.csv','f0203_f2.csv',\n",
    "\t\t\t  'f0102_f2.csv','f0001_f2.csv','f9900f2.csv']\n",
    "\n",
    "#Columns of intrest\n",
    "colNames0616 = ['UNITID', 'F2A06', 'F2B01', 'F2B02', 'F2E021']\n",
    "colNames9906 = ['unitid', 'f2a06', 'f2b01', 'f2b02', 'f2e021']\n",
    "\n",
    "dfs = [\"\"]*17\n",
    "for i in range(len(file_names)):\n",
    "\tprint(file_names[i])\n",
    "\tdfs[i] = pd.read_csv(file_names[i], encoding='latin-1')\n",
    "\tif i < 10:\n",
    "\t\tdfs[i] = dfs[i][colNames0616]\n",
    "\telse:\n",
    "\t\tdfs[i] = dfs[i][colNames9906]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID', 'ASSETS', 'REVENUE', 'EXPENSES', 'RESEARCH']\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID']+[file_names[i][1:5] + '_' + dfs[i].columns[j] for j in range(1,len(dfs[i].columns))]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i]['UNITID'] = dfs[i]['UNITID'].apply(lambda x: int(x))\n",
    "\n",
    "df_result = dfs[0]\n",
    "for i in range(1,len(dfs)):\n",
    "\tdf_result = pd.merge(df_result, dfs[i], left_on='UNITID', right_on='UNITID', how='inner')\n",
    "\n",
    "\n",
    "print(df_result)\n",
    "df_result.to_csv('./not_for_profit9916.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#List of file names\n",
    "file_names = ['f1516_f1a.csv','f1415_f1a.csv','f1314_f1a.csv','f1213_f1a.csv','f1112_f1a.csv','f1011_f1a.csv','f0910_f1a.csv',\n",
    "\t\t\t  'f0809_f1a.csv','f0708_f1a.csv','f0607_f1a.csv','f0506_f1a.csv','f0405_f1a.csv','f0304_f1a.csv','f0203_f1a.csv',\n",
    "\t\t\t  'f0102_f1a.csv']\n",
    "\n",
    "#Columns of intrest\n",
    "colNames0616 = ['UNITID', 'F1A18', 'F1D01', 'F1D02', 'F1C021']\n",
    "colNames0106 = ['unitid', 'f1a18', 'f1d01', 'f1d02', 'f1c021']\n",
    "\n",
    "dfs = [\"\"]*15\n",
    "for i in range(len(file_names)):\n",
    "\tprint(file_names[i])\n",
    "\tdfs[i] = pd.read_csv(file_names[i], encoding='latin-1')\n",
    "\tif i < 10:\n",
    "\t\tdfs[i] = dfs[i][colNames0616]\n",
    "\telse:\n",
    "\t\tdfs[i] = dfs[i][colNames0106]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID', 'ASSETS', 'REVENUE', 'EXPENSES', 'RESEARCH']\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID']+[file_names[i][1:5] + '_' + dfs[i].columns[j] for j in range(1,len(dfs[i].columns))]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i]['UNITID'] = dfs[i]['UNITID'].apply(lambda x: int(x))\n",
    "\n",
    "df_result = dfs[0]\n",
    "for i in range(1,len(dfs)):\n",
    "\tdf_result = pd.merge(df_result, dfs[i], left_on='UNITID', right_on='UNITID', how='inner')\n",
    "\n",
    "\n",
    "print(df_result)\n",
    "\n",
    "df_result.to_csv('./public0116.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "F_pu = pd.read_csv(\"public0116.csv\")\n",
    "F_pr = pd.read_csv(\"for_profit9916.csv\")\n",
    "F_npr = pd.read_csv(\"not_for_profit9916.csv\")\n",
    "\n",
    "F_pu['TYPE']  = \"public\"\n",
    "F_pr['TYPE']  = \"for-profit\"\n",
    "F_npr['TYPE'] = \"not-for-profit\"\n",
    "\n",
    "F = F_pr.append(F_npr)\n",
    "F = F.append(F_pu)\n",
    "F = F.drop(['0001_ASSETS', '0001_EXPENSES', '0001_RESEARCH', '0001_REVENUE', '9900_ASSETS', '9900_EXPENSES', '9900_RESEARCH', '9900_REVENUE'], axis=1)\n",
    "\n",
    "F = F[['UNITID', 'TYPE', \n",
    "\t   '1516_ASSETS', '1516_EXPENSES', '1516_REVENUE', '1516_RESEARCH',\n",
    "\t   '1415_ASSETS', '1415_EXPENSES', '1415_REVENUE', '1415_RESEARCH',\n",
    "\t   '1314_ASSETS', '1314_EXPENSES', '1314_REVENUE', '1314_RESEARCH',\n",
    "\t   '1213_ASSETS', '1213_EXPENSES', '1213_REVENUE', '1213_RESEARCH',\n",
    "\t   '1112_ASSETS', '1112_EXPENSES', '1112_REVENUE', '1112_RESEARCH',\n",
    "\t   '1011_ASSETS', '1011_EXPENSES', '1011_REVENUE', '1011_RESEARCH',\n",
    "\t   '0910_ASSETS', '0910_EXPENSES', '0910_REVENUE', '0910_RESEARCH',\n",
    "\t   '0809_ASSETS', '0809_EXPENSES', '0809_REVENUE', '0809_RESEARCH',\n",
    "\t   '0708_ASSETS', '0708_EXPENSES', '0708_REVENUE', '0708_RESEARCH',\n",
    "\t   '0607_ASSETS', '0607_EXPENSES', '0607_REVENUE', '0607_RESEARCH',\n",
    "\t   '0506_ASSETS', '0506_EXPENSES', '0506_REVENUE', '0506_RESEARCH',\n",
    "\t   '0405_ASSETS', '0405_EXPENSES', '0405_REVENUE', '0405_RESEARCH',\n",
    "\t   '0304_ASSETS', '0304_EXPENSES', '0304_REVENUE', '0304_RESEARCH',\n",
    "\t   '0203_ASSETS', '0203_EXPENSES', '0203_REVENUE', '0203_RESEARCH',\n",
    "\t   '0102_ASSETS', '0102_EXPENSES', '0102_REVENUE', '0102_RESEARCH',]]\n",
    "\n",
    "print('---------F---------')\n",
    "print(F.columns)\n",
    "print(F.shape)\n",
    "print('--------------------')\n",
    "\n",
    "\n",
    "F.to_csv('./university_financial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "#List of file names\n",
    "file_names = ['./sfa1516.csv','./sfa1415.csv','./sfa1314.csv','./sfa1213.csv','./sfa1112.csv','./sfa1011.csv','./sfa0910.csv',\n",
    "\t\t\t  './sfa0809.csv','./sfa0708.csv','./sfa0607.csv','./sfa0506.csv','./sfa0405.csv','./sfa0304.csv','./sfa0203.csv',\n",
    "\t\t\t  './sfa0102.csv','./sfa0001s.csv','./sfa9900s.csv']\n",
    "\n",
    "#Columns of intrest\n",
    "colNames0616 = ['UNITID', 'ANYAIDN', 'LOAN_A', 'LOAN_N', 'FGRNT_N', 'FGRNT_A', 'SGRNT_N', 'SGRNT_A', 'IGRNT_N', 'IGRNT_A']\n",
    "colNames9906 = ['unitid', 'anyaidn', 'loan_a', 'loan_n', 'fgrnt_n', 'fgrnt_a', 'sgrnt_n', 'sgrnt_a', 'igrnt_n', 'igrnt_a']\n",
    "\n",
    "\n",
    "# Poor formating on sfa0910.csv, must be processed individualy\n",
    "data = []\n",
    "for s in open('./sfa0910.csv', 'r'):\n",
    "\tl = []\n",
    "\tline = s.split(',')\n",
    "\tl.append(line[0])\n",
    "\tl.append(line[60])\n",
    "\tl.append(line[122])\n",
    "\tl.append(line[116])\n",
    "\tl.append(line[76])\n",
    "\tl.append(line[82])\n",
    "\tl.append(line[100])\n",
    "\tl.append(line[106])\n",
    "\tl.append(line[108])\n",
    "\tl.append(line[114])\n",
    "\tdata.append(l)\n",
    "\n",
    "cols = data.pop(0)\n",
    "df = pd.DataFrame(data, columns=cols)\n",
    "\n",
    "# making all files into a list of dataframes \n",
    "dfs = [\"\"]*17\n",
    "for i in range(len(file_names)):\n",
    "\tif i == 6:\n",
    "\t\tcontinue\n",
    "\tdfs[i] = pd.read_csv(file_names[i], encoding='latin-1')\n",
    "\tif i < 10:\n",
    "\t\tdfs[i] = dfs[i][colNames0616]\n",
    "\telse:\n",
    "\t\tdfs[i] = dfs[i][colNames9906]\n",
    "\n",
    "dfs[6] = df\n",
    "\n",
    "# set lower case column names to upper\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i].columns = ['UNITID']+[file_names[i][5:9] + '_' + dfs[i].columns[j].upper() for j in range(1,len(dfs[i].columns))]\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "\tdfs[i]['UNITID'] = dfs[i]['UNITID'].apply(lambda x: int(x))\n",
    "\n",
    "\n",
    "df_result = dfs[0]\n",
    "for i in range(1,len(dfs)):\n",
    "\tdf_result = pd.merge(df_result, dfs[i], left_on='UNITID', right_on='UNITID', how='inner')\n",
    "\n",
    "print(df_result)\n",
    "\n",
    "df_result.to_csv('./sfa9916.csv')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# file on university type from financial file\n",
    "df_type = pd.read_csv(\"./../university_financial/university_financial0116.csv\", index_col='Unnamed: 0')\n",
    "df_type = df_type[['UNITID', 'TYPE']]\n",
    "\n",
    "# retrieve sfa data\n",
    "df_sfa = pd.read_csv(\"./sfa9916.csv\", index_col='Unnamed: 0')\n",
    "\n",
    "# merge on id\n",
    "df_result = pd.merge(df_type, df_sfa, left_on='UNITID', right_on='UNITID', how='inner')\n",
    "\n",
    "# save to file\n",
    "df_result.to_csv('./student_financial_aid.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "nur=pd.read_csv(\"national_universities_rankings.csv\",encoding = \"ISO-8859-1\")\n",
    "hd2016=pd.read_csv(\"hd2016.csv\",encoding = \"ISO-8859-1\")\n",
    "nur=nur[[\"name\",\"rank\"]]\n",
    "l=[]\n",
    "for index,row in nur.iterrows():\n",
    "    name1=row['name']\n",
    "    for index1,row1 in hd2016.iterrows():\n",
    "        name2=row1['INSTNM']\n",
    "        similiar=fuzz.ratio(name1, name2)\n",
    "        if similiar>95:\n",
    "            line=[row['name'],row['rank'],row1['INSTNM'],row1['UNITID']]\n",
    "\n",
    "            l.append(line)\n",
    "#print(len(l))\n",
    "ranked_schools=pd.DataFrame(data = l , columns=['name','Rank','dup','UNITID'])\n",
    "ranked_schools = ranked_schools.drop('dup', 1)\n",
    "ranked_schools.to_csv(\"schools_ranking.csv\", sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "listofcsv=[\n",
    "\"effy2016.csv\",\n",
    "\"effy2015.csv\",\n",
    "\"effy2014.csv\",\n",
    "\"effy2013.csv\",\n",
    "\"effy2012.csv\",\n",
    "\"effy2011.csv\",\n",
    "\"effy2010.csv\",\n",
    "\"effy2009.csv\",\n",
    "\"effy2008.csv\",\n",
    "\"effy2007.csv\",\n",
    "\"effy2006.csv\",\n",
    "\"effy2005.csv\",\n",
    "\"effy2004.csv\",\n",
    "\"effy2003.csv\",\n",
    "\"effy2002.csv\",\n",
    "\"ef2001d1.csv\",\n",
    "]\n",
    "\n",
    "list=[[]]\n",
    "len(listofcsv)\n",
    "for i in range(len(listofcsv)):\n",
    "    enrollment=pd.read_csv(listofcsv[i])\n",
    "    if i <9:\n",
    "        enrollment = enrollment[[\"UNITID\",\"EFYTOTLT\"]]\n",
    "        enrollment=enrollment.groupby('UNITID').agg({ 'EFYTOTLT': 'sum'})\n",
    "        list.append(enrollment)\n",
    "    elif i==9:\n",
    "        enrollment = enrollment[[\"UNITID\",\"FYRACE24\"]]\n",
    "        enrollment=enrollment.groupby('UNITID').agg({ 'FYRACE24': 'sum'})\n",
    "        list.append(enrollment)\n",
    "    elif 9<i<15:\n",
    "        enrollment = enrollment[[\"unitid\",\"fyrace24\"]]\n",
    "        enrollment=enrollment.groupby('unitid').agg({ 'fyrace24': 'sum'})\n",
    "        list.append(enrollment)\n",
    "    else:\n",
    "        enrollment = enrollment[[\"unitid\",\"fyrace17\"]]\n",
    "        enrollment=enrollment.groupby('unitid').agg({ 'fyrace17': 'sum'})\n",
    "        list.append(enrollment)\n",
    "\n",
    "merged_enrollment =pd.merge(list[1], list[2], left_index=True, right_index=True)\n",
    "for i in range(3, 17):\n",
    "    thirdlist=list[i]\n",
    "    merged_enrollment =pd.merge(merged_enrollment, thirdlist, left_index=True, right_index=True)\n",
    "print(merged_enrollment)\n",
    "\n",
    "name_enrollment=[\"en2016\",\"en2015\",\"en2014\",\"en2013\",\"en2012\",\"en2011\",\"en2010\",\"en2009\"\n",
    "      ,\"en2008\",\"en2007\",\"en2006\",\"en2005\",\"en2004\",\"en2003\",\"en2002\",\"en2001\"]\n",
    "merged_enrollment.columns = name_enrollment\n",
    "print(merged_enrollment)\n",
    "for i in name_enrollment:\n",
    "    merged_enrollment.at['Total', i] = merged_enrollment[i].sum()\n",
    "print (merged_enrollment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list_gr=[\"gr2016.csv\",\"gr2015_rv.csv\",\"gr2014.csv\",\"gr2013.csv\",\"gr2012.csv\",\"gr2011.csv\",\"gr2010.csv\",\"gr2009.csv\"\n",
    "      ,\"gr2008.csv\",\"gr2007.csv\",\"gr2006.csv\",\"gr2005.csv\",\"gr2004.csv\",\"gr2003.csv\",\"gr2002.csv\",\"gr2001.csv\"]\n",
    "cursor=0\n",
    "count=[[]]\n",
    "for i in list_gr:\n",
    "    name = pd.read_csv(i)\n",
    "    if cursor<9:\n",
    "        l=name[[\"UNITID\",\"GRTOTLT\"]]\n",
    "        l=l.groupby('UNITID').agg({ 'GRTOTLT': 'sum'})\n",
    "        count.append(l)\n",
    "        cursor+=1\n",
    "    else:\n",
    "        l=name[[\"unitid\",\"grrace24\"]]\n",
    "        l=l.groupby('unitid').agg({ 'grrace24': 'sum'})\n",
    "        count.append(l)\n",
    "\n",
    "        \n",
    "len(count)\n",
    "first=count[1]\n",
    "second=count[2]\n",
    "\n",
    "merged_gr =pd.merge(first, second, left_index=True, right_index=True, how='inner')\n",
    "for i in range(3, 17):\n",
    "    third_list=count[i]\n",
    "    merged_gr =pd.merge(merged_gr, third_list, left_index=True, right_index=True)\n",
    "    \n",
    "colname=[\"gr2016\",\"gr2015\",\"gr2014\",\"gr2013\",\"gr2012\",\"gr2011\",\"gr2010\",\"gr2009\"\n",
    "      ,\"gr2008\",\"gr2007\",\"gr2006\",\"gr2005\",\"gr2004\",\"gr2003\",\"gr2002\",\"gr2001\"]\n",
    "merged_gr.columns = colname\n",
    "print(merged_gr)\n",
    "\n",
    "for i in colname:\n",
    "    merged_gr.at['Total', i] = merged_gr[i].sum()\n",
    "print (merged_gr)\n",
    "\n",
    "y_gr=merged_gr.tail(1).values.tolist()\n",
    "merged_gr['UNITID'] = merged_gr.index\n",
    "merged_gr.to_csv(\"GraduationRate_data.csv\", sep=',',encoding='utf-8')\n",
    "merged_enrollment['UNITID'] = merged_enrollment.index\n",
    "merged_enrollment.to_csv(\"Enrollment_data.csv\", sep=',',encoding='utf-8')\n",
    "education_result =pd.merge(merged_gr, merged_enrollment, left_index=True, right_index=True, how='inner')\n",
    "education_result.drop('UNITID_x', axis=1, inplace=True)\n",
    "education_result.rename(columns={'UNITID_y':'UNITID'}, inplace=True)\n",
    "print(education_result)\n",
    "financial_data = pd.read_csv('university_financial.csv', index_col=0)\n",
    "financial_data = financial_data[[\"UNITID\",\"TYPE\"]]\n",
    "merge_all =pd.merge(financial_data, education_result, left_on='UNITID', right_on='UNITID', how='inner')\n",
    "print(merge_all)\n",
    "merge_all.to_csv(\"graduationAndEnrollment.csv\", sep=',',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#import data\n",
    "df_enroll_grad       = pd.read_csv('graduationAndEnrollment.csv').drop('Unnamed: 0', axis=1)\n",
    "df_uni_financial     = pd.read_csv('university_financial.csv').drop(['Unnamed: 0', 'TYPE'], axis=1)\n",
    "df_uni_financial_aid = pd.read_csv('student_financial_aid.csv').drop(['Unnamed: 0', 'TYPE'], axis=1)\n",
    "df_uni_rating        = pd.read_csv('schools_ranking.csv')[['Rank', 'UNITID']]\n",
    "\n",
    "for col1 in df_uni_financial_aid.columns:\n",
    "    if not(col1[0].isdigit() and col1[5:] in [\"IGRNT_N\",'LOAN_N', 'FGRNT_N', 'SGRNT_N']):\n",
    "        continue\n",
    "    for col2 in df_uni_financial_aid.columns:\n",
    "        if not(col2[0].isdigit() and col2[:4] == col1[:4] and col1[5:9] == col2[5:9]):\n",
    "            continue\n",
    "        df_uni_financial_aid[col2[:-1] + \"T\"] = df_uni_financial_aid[col1]*df_uni_financial_aid[col2]\n",
    "\n",
    "for col in df_uni_financial_aid.columns:\n",
    "    if col[-2:] == \"_N\" or col[-2:] == \"_A\":\n",
    "        df_uni_financial_aid = df_uni_financial_aid.drop(col,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# inner merge data with key = UNITID; --> 2182 entries\n",
    "df = pd.merge(df_enroll_grad, df_uni_financial, left_on='UNITID', right_on='UNITID', how='inner')\n",
    "df = pd.merge(df, df_uni_financial_aid, left_on='UNITID', right_on='UNITID', how='inner')\n",
    "df = pd.merge(df, df_uni_rating, left_on='UNITID', right_on='UNITID', how=\"left\")\n",
    "\n",
    "\n",
    "df['Rank'] = df['Rank'].fillna(value=181)\n",
    "\n",
    "# change naming of columns to follow same naming convention\n",
    "cols = df.columns.tolist()\n",
    "for i in range(len(cols)):\n",
    "    if cols[i][0] == 'g':\n",
    "        endYear = cols[i][-2:]\n",
    "        beginingYear = str(int(endYear)-1).zfill(2)\n",
    "        cols[i] = beginingYear + endYear + '_' + 'GR'\n",
    "    elif cols[i][0] == 'e':\n",
    "        endYear = cols[i][-2:]\n",
    "        beginingYear = str(int(endYear)-1).zfill(2)\n",
    "        cols[i] = beginingYear + endYear + '_' + 'EN'\n",
    "df.columns = cols\n",
    "\n",
    "# remove years that are not available for all datasets (enrollment and graduations start at 00-01)\n",
    "for col in cols:\n",
    "    if col[0].isdigit() and int(col[0]) > 1: #any school year (<FallYY><SpringYY>) that starts with 2 or more --> before 2000\n",
    "        df = df.drop(col,axis=1)\n",
    "    if col[:2] == '00':\n",
    "        df = df.drop(col,axis=1)\n",
    "\n",
    "#Drop rows missing data\n",
    "df = df.dropna(how='any')        \n",
    "\n",
    "# manipulate each column to be percentage change from last year\n",
    "rows = []\n",
    "for idx, row in df.iterrows():\n",
    "    temp = [row['UNITID'], row['TYPE'], row['Rank']]\n",
    "    for var in [\"_GR\", \"_EN\", \"_ASSETS\", \"_EXPENSES\", \"_REVENUE\", \"_RESEARCH\", \"_ANYAIDN\",\"_LOAN_T\", \"_FGRNT_T\", \"_SGRNT_T\", \"_IGRNT_T\",]:\n",
    "        for i in range(1,15):\n",
    "            prevYear = str(int(i)).zfill(2)   + str(int(i+1)).zfill(2) + var\n",
    "            currYear = str(int(i+1)).zfill(2) + str(int(i+2)).zfill(2) + var\n",
    "            actual_increase = 0.01\n",
    "            percent_increase = 0.01\n",
    "            # if previous year is 0, assume that it did not change from previous year\n",
    "            if row[prevYear] != 0:\n",
    "                actual_increase  = row[currYear] - row[prevYear]\n",
    "                percent_increase = (actual_increase / row[prevYear])*100\n",
    "                \n",
    "            temp.append(percent_increase)\n",
    "    rows.append(temp)\n",
    "\n",
    "# get columns for percentage change df\n",
    "cols = [\"UNITID\", 'TYPE', 'Rank']\n",
    "for var in [\"_GR\", \"_EN\", \"_ASSETS\", \"_EXPENSES\", \"_REVENUE\", \"_RESEARCH\", \"_ANYAIDN\",\"_LOAN_T\", \"_FGRNT_T\", \"_SGRNT_T\", \"_IGRNT_T\",]:\n",
    "        for i in range(1,15):\n",
    "            currYear = str(int(i+1)).zfill(2) + str(int(i+2)).zfill(2) + var\n",
    "            cols.append(currYear)\n",
    "\n",
    "#Generate the percentage change df  \n",
    "df_percent_change_all_years = pd.DataFrame(rows, columns=cols)\n",
    "df_percent_change_all_years\n",
    "\n",
    "df_percent_change_all_years.to_csv(\"./percentage_change_all_vars.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
